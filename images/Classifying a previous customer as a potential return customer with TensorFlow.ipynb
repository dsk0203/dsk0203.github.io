{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a machine learning algorithm to see if a customer will buy again from an audiobook app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\Dylan\\Desktop\\ML\\AudioBookData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>873</th>\n",
       "      <th>2160</th>\n",
       "      <th>2160.1</th>\n",
       "      <th>10.13</th>\n",
       "      <th>10.13.1</th>\n",
       "      <th>0</th>\n",
       "      <th>8.91</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>2808</td>\n",
       "      <td>6.66</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>705</td>\n",
       "      <td>324.0</td>\n",
       "      <td>324</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>391</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>15.31</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>819</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1296</td>\n",
       "      <td>7.11</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14078</td>\n",
       "      <td>27398</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>7.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14079</td>\n",
       "      <td>28220</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14080</td>\n",
       "      <td>28671</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1080</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14081</td>\n",
       "      <td>31134</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14082</td>\n",
       "      <td>32832</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14083 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         873    2160  2160.1  10.13  10.13.1  0  8.91   0.1  0.2  0.3  0.4  1\n",
       "0        611  1404.0    2808   6.66    13.33  1  6.50  0.00  0.0    0  182  1\n",
       "1        705   324.0     324  10.13    10.13  1  9.00  0.00  0.0    1  334  1\n",
       "2        391  1620.0    1620  15.31    15.31  0  9.00  0.00  0.0    0  183  1\n",
       "3        819   432.0    1296   7.11    21.33  1  9.00  0.00  0.0    0    0  1\n",
       "4        138  2160.0    2160  10.13    10.13  1  9.00  0.00  0.0    0    5  1\n",
       "...      ...     ...     ...    ...      ... ..   ...   ...  ...  ...  ... ..\n",
       "14078  27398  2160.0    2160   7.99     7.99  0  8.91  0.00  0.0    0   54  0\n",
       "14079  28220  1620.0    1620   5.33     5.33  1  9.00  0.61  0.0    0    4  0\n",
       "14080  28671  1080.0    1080   6.55     6.55  1  6.00  0.29  0.0    0   29  0\n",
       "14081  31134  2160.0    2160   6.14     6.14  0  8.91  0.00  0.0    0    0  0\n",
       "14082  32832  1620.0    1620   5.33     5.33  1  8.00  0.38  0.0    0   90  0\n",
       "\n",
       "[14083 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load w pandas to see if need to make changes\n",
    "\n",
    "# looks decent, needs standardization \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column meanings\n",
    "\n",
    "# 0.) Index (pandas created)\n",
    "# 1.) Customer ID\n",
    "# 2.) Book Length overall\n",
    "# 3.) Book length used\n",
    "# 4.) Price\n",
    "# 5.) Price average\n",
    "# 6.) Review (0 1 binary yes/no)\n",
    "# 7.) Rating of that review 0 if not\n",
    "# 8.) Minutes Listened\n",
    "# 9.) Completion %\n",
    "# 10.) Support Requests\n",
    "# 11.) Last visited minute purchase date (days inactivte)\n",
    "# 12.) Binary Y/N if bought in last 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertdata = np.loadtxt(r'C:\\Users\\Dylan\\Desktop\\ML\\AudioBookData.csv', delimiter = ',')\n",
    "converted = convertdata[:,1:-1]\n",
    "targetsALL = convertdata[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total list\n",
    "numofonetargets = int(np.sum(targetsALL))\n",
    "\n",
    "\n",
    "# create the counter\n",
    "counter = 0\n",
    "\n",
    "# storage\n",
    "indices_to_remove = []\n",
    "\n",
    "# loop through all\n",
    "for i in range (targetsALL.shape[0]):\n",
    "    \n",
    "    # find the values equal to 0\n",
    "    if targetsALL[i] == 0:\n",
    "    \n",
    "    # increase the counter   \n",
    "        \n",
    "        counter +=1\n",
    "        \n",
    "        if counter > numofonetargets:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(converted, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targetsALL, indices_to_remove, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3579\n",
      "447\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# 80 10 10 split\n",
    "\n",
    "# counts\n",
    "\n",
    "train_samples_count = int(.8 * samples_count)\n",
    "vali_samples_count = int(.1 * samples_count)\n",
    "test_samples_count = int(.1 * samples_count)\n",
    "\n",
    "# extract from main\n",
    "\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "vali_inputs = shuffled_inputs[train_samples_count:train_samples_count+vali_samples_count]\n",
    "vali_targets = shuffled_targets[train_samples_count:train_samples_count+vali_samples_count]\n",
    "\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+vali_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+vali_samples_count:]\n",
    "\n",
    "print(train_samples_count)\n",
    "print(vali_samples_count)\n",
    "print(test_samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('AudioBook_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('AudioBook_vali', inputs=vali_inputs, targets=vali_targets)\n",
    "np.savez('AudioBook_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Dylan\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loads (incase want different files, model is highly re-usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('AudioBook_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npztemp = np.load('AudioBook_vali.npz')\n",
    "\n",
    "validation_inputs = npztemp['inputs'].astype(np.float)\n",
    "validation_targets = npztemp['targets'].astype(np.int)\n",
    "\n",
    "npztemp1 = np.load('AudioBook_test.npz')\n",
    "\n",
    "test_inputs = npztemp1['inputs'].astype(np.float)\n",
    "test_targets = npztemp1['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3579 samples, validate on 447 samples\n",
      "Epoch 1/100\n",
      "3579/3579 - 0s - loss: 0.4900 - accuracy: 0.8335 - val_loss: 0.3876 - val_accuracy: 0.8613\n",
      "Epoch 2/100\n",
      "3579/3579 - 0s - loss: 0.3377 - accuracy: 0.8810 - val_loss: 0.3205 - val_accuracy: 0.8725\n",
      "Epoch 3/100\n",
      "3579/3579 - 0s - loss: 0.2964 - accuracy: 0.8927 - val_loss: 0.3041 - val_accuracy: 0.8814\n",
      "Epoch 4/100\n",
      "3579/3579 - 0s - loss: 0.2779 - accuracy: 0.9003 - val_loss: 0.2979 - val_accuracy: 0.8770\n",
      "Epoch 5/100\n",
      "3579/3579 - 0s - loss: 0.2690 - accuracy: 0.8994 - val_loss: 0.2972 - val_accuracy: 0.8747\n",
      "Epoch 6/100\n",
      "3579/3579 - 0s - loss: 0.2605 - accuracy: 0.9030 - val_loss: 0.2864 - val_accuracy: 0.8792\n",
      "Epoch 7/100\n",
      "3579/3579 - 0s - loss: 0.2555 - accuracy: 0.9042 - val_loss: 0.2828 - val_accuracy: 0.8837\n",
      "Epoch 8/100\n",
      "3579/3579 - 0s - loss: 0.2499 - accuracy: 0.9053 - val_loss: 0.2788 - val_accuracy: 0.8814\n",
      "Epoch 9/100\n",
      "3579/3579 - 0s - loss: 0.2478 - accuracy: 0.9064 - val_loss: 0.2749 - val_accuracy: 0.8814\n",
      "Epoch 10/100\n",
      "3579/3579 - 0s - loss: 0.2451 - accuracy: 0.9084 - val_loss: 0.2744 - val_accuracy: 0.8814\n",
      "Epoch 11/100\n",
      "3579/3579 - 0s - loss: 0.2417 - accuracy: 0.9098 - val_loss: 0.2831 - val_accuracy: 0.8859\n",
      "Epoch 12/100\n",
      "3579/3579 - 0s - loss: 0.2399 - accuracy: 0.9100 - val_loss: 0.2706 - val_accuracy: 0.8859\n",
      "Epoch 13/100\n",
      "3579/3579 - 0s - loss: 0.2367 - accuracy: 0.9131 - val_loss: 0.2713 - val_accuracy: 0.8881\n",
      "Epoch 14/100\n",
      "3579/3579 - 0s - loss: 0.2351 - accuracy: 0.9137 - val_loss: 0.2673 - val_accuracy: 0.8881\n",
      "Epoch 15/100\n",
      "3579/3579 - 0s - loss: 0.2362 - accuracy: 0.9117 - val_loss: 0.2658 - val_accuracy: 0.8837\n",
      "Epoch 16/100\n",
      "3579/3579 - 0s - loss: 0.2325 - accuracy: 0.9131 - val_loss: 0.2633 - val_accuracy: 0.8971\n",
      "Epoch 17/100\n",
      "3579/3579 - 0s - loss: 0.2319 - accuracy: 0.9153 - val_loss: 0.2640 - val_accuracy: 0.8949\n",
      "Epoch 18/100\n",
      "3579/3579 - 0s - loss: 0.2309 - accuracy: 0.9142 - val_loss: 0.2640 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ddc2ae4b48>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Sequential used to start layering the model (STACK LAYERS)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # dot product math to find the bias and weights + activation function\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    # second layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    # output layer want probabilities so use softmax\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax'),\n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(train_inputs,\n",
    "         train_targets,\n",
    "         batch_size = BATCH_SIZE,\n",
    "         epochs = EPOCHS,\n",
    "        callbacks=[early_stopping],\n",
    "         validation_data = (validation_inputs, validation_targets),\n",
    "         verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can classify 89.26 % of customers on if they will return or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 0s 54us/sample - loss: 0.2425 - accuracy: 0.9129\n"
     ]
    }
   ],
   "source": [
    "test_loss,  test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying this new model to the business ..\n",
    "\n",
    "model.predict_on_batch(*company gives data on a potential canidate*)\n",
    "\n",
    "model returns 0 or 1, telling marketing team to invest on advertising or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
